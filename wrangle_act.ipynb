{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeLoveDogs Twitter data analysis\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#assessing\">Assessing Data</a></li>\n",
    "<li><a href=\"#cleaning\">Data Cleaning</a></li>\n",
    "<li><a href=\"#storing\">Storing Data</a></li>\n",
    "<li><a href=\"#analysis\">Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Twitter API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "# Data Wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs Twitter archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter-archive-enhanced.csv', dtype= {'tweet_id': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'images_pred'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(os.path.join(folder_name, url.split('/')[-1]), mode='wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(r'images_pred/image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets' retweet count and favorite (\"like\") count (at minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the metadata in the API call I used: https://gist.github.com/dev-techmoe/ef676cdd03ac47ac503e856282077bf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build and convert to a DataFrame later\n",
    "data_tweet = {}\n",
    "data_tweet['tweet'] = []\n",
    "ranking = 0\n",
    "start = timeit.timeit()\n",
    "for tweetid in df.tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(tweetid, tweet_mode = 'extended', wait_on_rate_limit= True, wait_on_rate_limit_notify = True)\n",
    "        retweets = str(tweet.retweet_count)\n",
    "        likes = str(tweet.favorite_count)\n",
    "        data_tweet['tweet'].append({'tweet_id': tweetid,\n",
    "                                    'retweet': retweets,\n",
    "                                    'likes': likes})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(str(ranking) + \"_\" + tweetid + \": \" + str(e))\n",
    "        \n",
    "end = timeit.timeit()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few tweet ids failed to retrieve data, but the above code run as normal. Now writting the content as JSON in a .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    json.dump(data_tweet, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One extra step is needed here: to use the JSON library to transform the json-format content in a dataframe-friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tweet_json.txt') as obj:\n",
    "    data = json.load(obj)\n",
    "    print(type(data))\n",
    "    df_pop = pd.DataFrame.from_dict(data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json.txt') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(len(data['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what is missing\n",
    "miss_tweet = []\n",
    "with open('tweet_json.txt') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for p in data['tweet']:\n",
    "        miss_tweet.append(p['tweet_id'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(miss_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df.tweet_id) - set(miss_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = df[df['tweet_id'] == '837012587749474308'].expanded_urls.astype(str)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could not find those tweets manually on Twitter.com, it seems they have been deleted or the tweet id is faulty. \n",
    "We should remove those tweets from the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "# Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 dataframes:\n",
    "\n",
    "- `archive` the archive of tweets\n",
    "- `prediction`, image prediction algo results\n",
    "- `likes and count of retweets`, downloaded number of retweets and likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive of the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.in_reply_to_user_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.tweet_id[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['retweeted_status_id'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'retweeted_status_id' and 'retweeted_status_timestamp' don't bring much value to the analysis in the current context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('rating_denominator != \"10\"').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'rating_numerator' has values < 10 (not the logic) => after manual check noticed that it may be either because the numerator has been scrapped from a number in the text that is not the rating or the user didn't follow the rating system underlying logic. As a result, to maintain consistency and make the tweets comparable, drop the lanies with numerator < 10\n",
    "- 'rating_denominator' has values different from 10 => same as above, drop the lines with values different from 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'in_reply_to_status_id' and 'in_reply_to_user_id' have only 78 values\n",
    "Timestamp not easy to read\n",
    "Text is raw\n",
    "Source is HTML format\n",
    "'retweeted_status_id' and 'retweeted_status_user_id' not actionable\n",
    "Doggo/Fluffer/Puppo etc => same variable, should be in the same column\n",
    "'rating_numerator' has values < 10 (not the logic)\n",
    "'denominator has various values when it should be 10 for consistency (text parsing issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expanded_urls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['expanded_urls'] == 'https://twitter.com/dog_rates/status/667866724293877760/photo/1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['expanded_urls'] == 'https://twitter.com/dog_rates/status/698195409219559425/photo/1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.expanded_urls.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are some duplicates generated by retweets and comments in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.match(r'^RT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expanded_urls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['expanded_urls'] == 'https://www.gofundme.com/my-puppys-double-cataract-surgery,https://twitter.com/dog_rates/status/825026590719483904/photo/1,https://twitter.com/dog_rates/status/825026590719483904/photo/1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Gofundme links for people raising money for their dogs surgery. Some commercial links, often because of partnerships with the Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dogs' names are not populated, a lost of 'a' and a few 'the' which doesn't sounds like a dog's name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Image prediction dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the first prediction is not a dog it may be that the second or third one is. Although, the confidence is very low in that case. To maintain reliability, we should probably drop the second and third suggestions. Then, we should clean the first suggestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.query('p1_dog == False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.p2_dog.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns p1, p2, p3 have values which are not dog breeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.jpg_url.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred.jpg_url == 'https://pbs.twimg.com/media/CrXhIqBW8AA6Bse.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUplicates due to retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweets and likes dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessment Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues:\n",
    "\n",
    "##### `archive` table\n",
    "- Columns 'in_reply_to_status_id' and 'in_reply_to_user_id' have only 78 values. Columns 'retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp' only have 181\n",
    "- Timestamp column not easy to deal with\n",
    "- Duplicates generated by retweets and comments\n",
    "- Many dogs' names are not populated, a lost of 'a' which doesn't sounds like a dog's name\n",
    "- Source is HTML format\n",
    "- 'rating_numerator' has values < 10 (not the logic)\n",
    "- 'rating_denominator' has values different from 10 (text parsing issue)\n",
    "\n",
    "##### `prediction` table\n",
    "- Columns p1, p2, p3 have values which are not dog breeds\n",
    "\n",
    "### Tidiness issues:\n",
    "\n",
    "##### `archive` table\n",
    "- df archive: The columns Doggo/Fluffer/Puppo are the same variable and should be consolidated in the same column\n",
    "\n",
    "##### `retweets and likes` table\n",
    "- Likes and count of retweet are attributes of the archived tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "df_pred_clean = df_pred.copy()\n",
    "df_pop_clean = df_pop.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: The columns Doggo/Fluffer/Puppo are the same variable and should be consolidated in the same column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Consolidate the different values from the column into on new column (the variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.melt(df_clean, id_vars=['tweet_id', \n",
    "                                      'in_reply_to_status_id',\n",
    "                                      'in_reply_to_user_id',\n",
    "                                      'timestamp', \n",
    "                                      'source', \n",
    "                                      'text', \n",
    "                                      'retweeted_status_id', \n",
    "                                      'retweeted_status_user_id',\n",
    "                                      'retweeted_status_timestamp',\n",
    "                                      'expanded_urls',\n",
    "                                      'rating_numerator', \n",
    "                                      'rating_denominator', \n",
    "                                      'name'],\n",
    "                                       var_name='dog_type')\n",
    "df_clean.drop(columns='dog_type', inplace=True)\n",
    "df_clean.rename(columns={'value' : 'dog_type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dog_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `retweets and likes` table: likes and count of retweet are attributes of the archived tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Merge the retweets and likes dataframe with the archive dataframe. Then, fill the NaN values generated by the discrepancies between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.tweet_id = df_pop.tweet_id.astype(str)\n",
    "df_clean = pd.merge(df_clean, df_pop,\n",
    "                            on=['tweet_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_clean.likes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likes and retweets have been marged as float. Moreover, some tweets don't have likes/retweets values to be attributted, resulting in NaN values. \n",
    "We need to fill in the missing values with the median to avoid skewing the data analysis.Then we will be able to convert the two columns into a integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling NaN with median value\n",
    "df_clean.likes.fillna(df_clean.likes.median(), inplace=True)\n",
    "df_clean.retweet.fillna(df_clean.retweet.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the likes and counts of retweet into integer\n",
    "df_clean.likes = df_clean.likes.astype(int)\n",
    "df_clean.retweet = df_clean.retweet.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: Columns 'in_reply_to_status_id' and 'in_reply_to_user_id' have only 78 values. Columns 'retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp' only have 181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Drop the columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['in_reply_to_status_id', \n",
    "                       'in_reply_to_user_id', \n",
    "                       'retweeted_status_id', \n",
    "                       'retweeted_status_user_id', \n",
    "                       'retweeted_status_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: Source is HTML format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Create a dictionnary with the different sources and more simple names. Apply a method to replace with the simple names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = {'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>' : 'Iphone',\n",
    "          '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>' : 'Web browser',\n",
    "         '<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>' : 'Vine',\n",
    "         '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>' : 'TweetDeck'\n",
    "         }\n",
    "\n",
    "df_clean.replace(source, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive`  Timestamp column not easy to deal with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Use timedate to convert to date, drop the time since it doesn't really bring much value to our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.timestamp = df_clean.timestamp.astype(str).str[:-15]\n",
    "df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_clean.timestamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: Duplicates generated by retweets and comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Drop the row generated with retweets and replies using regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean.text.str.contains(r'^(?!RT)')]\n",
    "df_clean = df_clean[df_clean.text.str.contains(r'^(?!@)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean[df_clean.text.str.contains(r'^RT')])\n",
    "print(df_clean[df_clean.text.str.contains(r'^@')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: Many dogs' names are not populated, a lost of 'a' which doesn't sounds like a dog's name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Replace the odd names with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[df_clean.name.str.islower(), 'name'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table: Numerator column has values lower than 10 (not the logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Filter for removing the rows with numerator lower than 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.query('rating_numerator >= 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.rating_numerator.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `archive` table:Denominator column has values different from 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "Set the value of the entire column to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['rating_denominator'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.rating_denominator.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet image predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `image prediction` table: The columns p1, p2 and p3 have values which are not dog breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Drop the columns for the second and third suggestions as their associated prediction likelihood is very low. Filter for True dogs suggestions to clean the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns\n",
    "df_pred_clean.drop(df_pred_clean.columns[6:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for True dog suggestions\n",
    "df_pred_clean = df_pred.query('p1_dog == True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_clean.p1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='storing'></a>\n",
    "# Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are storing the main dataframe into twitter_archive_master.csv\n",
    "\n",
    "An additional file is required for tidiness. Thus, we are storing the results of the images prediction algorithm into image_prediction.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('twitter_archive_master.csv', index=False)\n",
    "df_pred_clean.to_csv('image_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis will be broken down in 3 parts as follow:\n",
    "- **Dogs population insights**\n",
    "- **'Owners' popularity** (The grades given by the dog owners directly on the post. Very important but maybe not the most objective metric to look at...?)\n",
    "- **'Public' popularity** (Popularity in terms of likes and retweets, attributed by the public on Twitter. An interesting approach to understand who are the most famous dogs around)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the questions to answer are:\n",
    "\n",
    "**Which source are the dog lovers using to share their best pictures?** \n",
    "<br>**Which type of dogs gets the best grades 'out of 10'?**\n",
    "<br>**Which breeds of dogs are the most popular in terms of likes and retweets?**\n",
    "<br>**Has a type of dog been more popular than the others over time?**\n",
    "<br>**Are the types of dogs with good grades also popular in on Twitter?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloading the data from the CSV files\n",
    "df_clean = pd.read_csv('twitter_archive_master.csv', dtype={'tweet_id':'str'})\n",
    "df_pred_clean = pd.read_csv('image_prediction.csv', dtype={'tweet_id':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dogs population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be able to look specificaly at the dog type related metrics, let's create a dataframe with only the observations populated with a specific type\n",
    "df_clean_nona = df_clean.query('dog_type != \"None\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = df_clean_nona.dog_type.value_counts().index\n",
    "hue = sns.color_palette()[2]\n",
    "sns.countplot(y='dog_type', data= df_clean_nona, order=order, color=hue)\n",
    "plt.ylabel('Dog type')\n",
    "plt.xlabel('')\n",
    "plt.title('Population size per dog type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pupper represent the most important poopulation of dogs with a population of nearly 200. The floofers are the smallest population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the owner popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby('dog_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The puppos are receiving the best grades 'out of 10' on average, with an average of 12.2/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the public popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what the likes and retweets distributions look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.likes.hist(figsize=(12, 6), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.retweet.hist(figsize=(12, 6), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both distributions are very skewed on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum the likes per dog type?\n",
    "df_clean.groupby('dog_type').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The puppers are cumulating the most likes and retweets, but are twice as many as the doggos (dividing the denominator by 10 to get the number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby('dog_type').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite being a small portion of the total population, the puppos have an higher average number of likes around 22k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby('source').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People posting from an Iphone are on average receiving more likes. Although, The Vine-made and web browser-originated tweets are more retweeted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to develop the study to get further insights about the dog breeds, we need to merge the two dataframes on the tweet_id key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(df_clean, df_pred_clean, on=['tweet_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now group the new dataframe by dog breed and check the who is at the top of the rankings in terms of likes and retweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.groupby('p1').mean().sort_values('likes', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.groupby('p1').mean().sort_values('retweet', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black and Tan Coonhound and Standard Poodle are the most popular breed in terms of number of likes and number of retweets. They both rank first and second in those two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get further insight about the dogs popularity per type, let's add another feature which is the distribution of the type's population in terms of likes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = sns.stripplot(y='likes', x=df_clean_nona['dog_type'], data=df_clean_nona, jitter=True, dodge=True, alpha=0.5)\n",
    "ax.set_title('Distribution of the number of likes for each dog type',fontsize=18)\n",
    "ax.set_xlabel('Dog type',fontsize=18)\n",
    "ax.set_ylabel('Number of likes',fontsize=18)\n",
    "ax.yaxis.grid(color='white')\n",
    "ax.xaxis.grid(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that of few doggos have received a landslide appraisal, as for a pupper and a puppo. But most of their peers have an average of 10k likes. The floofers are more rare than the other dog types. The most populated type is the pupper type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I would like to understand if the dog's owners and the public get along when it comes to rating those dogs. To find out, let's categorize the dogs in terms of owner's popularity and compare each category's public approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popularity per mark\n",
    "bin_edges = [ 0, 10, 11, 12, 1776]\n",
    "bin_names = [ 'Low', 'Medium', 'Moderate', 'High']\n",
    "df_clean['popularity'] = pd.cut(df_clean['rating_numerator'], bin_edges, labels=bin_names)\n",
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = df_clean.groupby('popularity').mean()\n",
    "category_df.reset_index(level=0, inplace=True)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_pop = category_df.sort_values('likes', ascending=False).iloc[:,0]\n",
    "\n",
    "sns.barplot(x='likes',y='popularity', data=category_df, order=order_pop, color= hue)\n",
    "plt.xlabel('Average number of likes')\n",
    "plt.ylabel('Popularity category')\n",
    "plt.title('Average number of likes (public popularity) per category of dog rate (owner popularity)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper quartile which represents the 25% of posts with the best grade are proven to be also the most popular among the users, receiving the highest average number of likes and retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dogs population insights**\n",
    "\n",
    "Most of the tweets are sharing puppers.\n",
    "\n",
    "- **'Owners' popularity** \n",
    "\n",
    "The puppos are on average receiving the best grades from their owners with an average of 12.2/10.\n",
    "\n",
    "- **'Public' popularity** \n",
    "\n",
    "The public appreciate the most the dogs' pictures posted from an Iphone, but share rather the post made with Vine and from a web browser.\n",
    "Among the breeds, the black and Tan Coonhound and the Standard Poodle are the most popular dogs for the Twitter users. The distribution of tweets popularity metrics are displaying a few extremely popular posts but overwhelmingly the dogs received a rather stable and low number of likes and retweets.\n",
    "Finally, there is a clear correlation between the owner's rates and the public's popularity: the quartile of dogs which received the highest owner's grades are also receiving the most likes on average from the dog lovers spending time on WeRateDogs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
